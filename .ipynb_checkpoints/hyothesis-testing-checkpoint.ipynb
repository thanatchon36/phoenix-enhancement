{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "pd.options.display.float_format = '{:,}'.format\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import numpy as np\n",
    "pd.options.display.float_format = '{:,}'.format\n",
    "\n",
    "import featuretools as ft\n",
    "import datetime\n",
    "\n",
    "#https://github.com/aschleg/hypothetical\n",
    "from hypothetical.hypothesis import BinomialTest, tTest\n",
    "\n",
    "from itertools import combinations \n",
    "  \n",
    "def rSubset(arr, r): \n",
    "  \n",
    "    # return list of all subsets of length r \n",
    "    # to deal with duplicate subsets use  \n",
    "    # set(list(combinations(arr, r)))\n",
    "    return list(combinations(arr, r)) \n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/defined_Data_Phoenix_Campaign_Enhancement.csv')\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_p_val(num):\n",
    "    if num < 0.05:\n",
    "        return True\n",
    "    if num >= 0.05:\n",
    "        return False\n",
    "    else:\n",
    "        return np.nan\n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "df_y = df[df['campaign_take_up'].str.contains('Y')]\n",
    "df_y = df_y[df_y['2018_15_2017_10'] == True].reset_index()[cols]\n",
    "\n",
    "cols = ['age_range','customer_gender','cus_marital_status']\n",
    "\n",
    "def hypothesis_testing_cols(cols):\n",
    "    start_time = time.time()\n",
    "    df_y['group_1'] = ''\n",
    "    df['temp_group'] = ''\n",
    "    for each in cols:\n",
    "        df_y['group_1'] = df_y['group_1'] + '_' + df_y[each]\n",
    "        df['temp_group'] = df['temp_group'] +  '_' + df[each]\n",
    "\n",
    "    df_y['group_1'] = df_y['group_1'].apply(lambda x: x[1:])\n",
    "    df['temp_group'] = df['temp_group'].apply(lambda x: x[1:])\n",
    "\n",
    "\n",
    "    group_1 = df_y['group_1'].value_counts().reset_index()\n",
    "    group_1.columns = ['group','total_sample']\n",
    "\n",
    "    for i in range(len(group_1)):\n",
    "        try:\n",
    "            group = group_1.loc[i]['group']\n",
    "            sample_2018 = df_y[(df_y['group_1'].str.contains(group,regex=False))&\n",
    "                (df_y['year']==2018)]\n",
    "            sample_2017 = df_y[(df_y['group_1'].str.contains(group,regex=False))&\n",
    "                (df_y['year']==2017)]\n",
    "\n",
    "            group_1.loc[i,'sample_2018_no'] = len(sample_2018)\n",
    "            group_1.loc[i,'sample_2017_no'] = len(sample_2017)\n",
    "            \n",
    "            ttest = tTest(y1=sample_2018['actual_offer_percent'], y2=sample_2017['actual_offer_percent'], var_equal=False, alternative = \"two-sided\")\n",
    "            test_summary = ttest.test_summary\n",
    "            p_val = test_summary['p-value']\n",
    "            group_1.loc[i,'two_sided_p_value'] = p_val\n",
    "            group_1.loc[i,'two_sided_t_statistic'] = test_summary['t-statistic']\n",
    "            group_1.loc[i,'two_sided_CI'] = str(test_summary['confidence interval'])\n",
    "            group_1.loc[i,'Act_per_2018_Mean'] = test_summary['Sample 1 Mean']\n",
    "            group_1.loc[i,'Act_per_2017_Mean'] = test_summary['Sample 2 Mean']\n",
    "            group_1.loc[i,'two_sided_des'] = test_summary['test description']\n",
    "\n",
    "            ttest = tTest(y1=sample_2018['campaign_premium'], y2=sample_2017['campaign_premium'], var_equal=False, alternative = \"greater\")\n",
    "            test_summary = ttest.test_summary\n",
    "            p_val = test_summary['p-value']\n",
    "            group_1.loc[i,'greater_p_value'] = p_val\n",
    "            group_1.loc[i,'greater_t_statistic'] = test_summary['t-statistic']\n",
    "            group_1.loc[i,'greater_CI'] = str(test_summary['confidence interval'])\n",
    "            group_1.loc[i,'premium_2018_Mean'] = test_summary['Sample 1 Mean']\n",
    "            group_1.loc[i,'premium_2017_Mean'] = test_summary['Sample 2 Mean']\n",
    "            group_1.loc[i,'greater_des'] = test_summary['test description']\n",
    "\n",
    "            premium_2018_y = df[(df['temp_group'].str.contains(group,regex=False))&\n",
    "                        (df['year']==2018) &\n",
    "                (df['campaign_take_up'] == 'Y')\n",
    "              ]['campaign_premium'].sum()\n",
    "\n",
    "            premium_2018_n = df[(df['temp_group'].str.contains(group,regex=False))&\n",
    "                        (df['year']==2018) &\n",
    "                (df['campaign_take_up'] == 'N')\n",
    "              ]['campaign_premium'].sum()\n",
    "\n",
    "            premium_2017_y = df[(df['temp_group'].str.contains(group,regex=False))&\n",
    "                        (df['year']==2017) &\n",
    "                (df['campaign_take_up'] == 'Y') &\n",
    "                    (df['2018_15_2017_10'] == True)\n",
    "              ]['campaign_premium'].sum()\n",
    "\n",
    "            premium_2017_n = df[(df['temp_group'].str.contains(group,regex=False))&\n",
    "                        (df['year']==2017) &\n",
    "                (df['campaign_take_up'] == 'N') &\n",
    "                    (df['2018_15_2017_10'] == True)\n",
    "              ]['campaign_premium'].sum()\n",
    "\n",
    "            y_2017 = premium_2017_y /(premium_2017_y + premium_2017_n)\n",
    "            y_2018 = premium_2018_y /(premium_2018_y + premium_2018_n)\n",
    "            y_score = y_2018 - y_2017\n",
    "\n",
    "            group_1.loc[i,'y_2017'] = y_2017*100\n",
    "            group_1.loc[i,'y_2018'] = y_2018*100\n",
    "            group_1.loc[i,'y_score'] = y_score*100\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    group_1['sample_2018_no'] = group_1['sample_2018_no'].astype(int)  \n",
    "    group_1['sample_2017_no'] = group_1['sample_2017_no'].astype(int)  \n",
    "\n",
    "    group_1['Act_per_2018_Mean'] = group_1['Act_per_2018_Mean'].apply(lambda x: round(x,2))\n",
    "    group_1['Act_per_2017_Mean'] = group_1['Act_per_2017_Mean'].apply(lambda x: round(x,2))\n",
    "    group_1['two_sided_p_value'] = group_1['two_sided_p_value'].apply(lambda x: round(x,3))\n",
    "    group_1['two_sided_t_statistic'] = group_1['two_sided_t_statistic'].apply(lambda x: round(x,2))\n",
    "\n",
    "    group_1['premium_2018_Mean'] = group_1['premium_2018_Mean'].apply(lambda x: round(x,2))\n",
    "    group_1['premium_2017_Mean'] = group_1['premium_2017_Mean'].apply(lambda x: round(x,2))\n",
    "    group_1['greater_p_value'] = group_1['greater_p_value'].apply(lambda x: round(x,3))\n",
    "    group_1['greater_t_statistic'] = group_1['greater_t_statistic'].apply(lambda x: round(x,2))\n",
    "\n",
    "    cols = group_1.columns\n",
    "    group_1 = group_1.reset_index()[cols]\n",
    "\n",
    "    group_1['not_equal_sig'] = group_1['two_sided_p_value'].apply(check_p_val)\n",
    "    group_1['greater_sig'] = group_1['greater_p_value'].apply(check_p_val)\n",
    "\n",
    "    return group_1\n",
    "\n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level-1 testing\n",
    "cols = ['age_range', 'customer_gender', 'cus_marital_status', 'annual_range','campaign_offer_product','risk_level'] \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "level_1 = pd.DataFrame()\n",
    "for each in cols:\n",
    "    testing_df = hypothesis_testing_cols([each])\n",
    "    level_1 = level_1.append(testing_df)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "level_1.to_csv('data/testReport_level_1.csv', index=False)\n",
    "\n",
    "level_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level- 2 testing\n",
    "start_time = time.time()\n",
    "\n",
    "arr = ['age_range', 'customer_gender', 'cus_marital_status', 'annual_range','campaign_offer_product','risk_level'] \n",
    "r = 2\n",
    "\n",
    "level_2 = pd.DataFrame()\n",
    "\n",
    "for each in rSubset(arr, r):\n",
    "    cols = [each_2 for each_2 in each]\n",
    "    \n",
    "    testing_df = hypothesis_testing_cols(cols)\n",
    "    level_2 = level_2.append(testing_df)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "level_2.to_csv('data/testReport_level_2.csv', index=False)\n",
    "\n",
    "level_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level- 3 testing\n",
    "start_time = time.time()\n",
    "\n",
    "arr = ['age_range', 'customer_gender', 'cus_marital_status', 'annual_range','campaign_offer_product','risk_level'] \n",
    "r = 3\n",
    "\n",
    "level_3 = pd.DataFrame()\n",
    "\n",
    "for each in rSubset(arr, r):\n",
    "    cols = [each_2 for each_2 in each]\n",
    "    \n",
    "    testing_df = hypothesis_testing_cols(cols)\n",
    "    level_3 = level_3.append(testing_df)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "level_3.to_csv('data/testReport_level_3.csv', index=False)\n",
    "\n",
    "level_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level- 4 testing\n",
    "start_time = time.time()\n",
    "\n",
    "arr = ['age_range', 'customer_gender', 'cus_marital_status', 'annual_range','campaign_offer_product','risk_level'] \n",
    "r = 4\n",
    "\n",
    "level_4 = pd.DataFrame()\n",
    "\n",
    "for each in rSubset(arr, r):\n",
    "    cols = [each_2 for each_2 in each]\n",
    "    \n",
    "    testing_df = hypothesis_testing_cols(cols)\n",
    "    level_4 = level_4.append(testing_df)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "level_4.to_csv('data/testReport_level_4.csv', index=False)\n",
    "\n",
    "level_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(level_1)\n",
    "len(level_2)\n",
    "len(level_3)\n",
    "len(level_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_all = pd.DataFrame()\n",
    "level_all = level_all.append(level_1).append(level_2).append(level_3).append(level_4)\n",
    "level_all['which_level'] = level_all['group'].apply(lambda x: len(x.split('_')))\n",
    "\n",
    "level_all = level_all[(level_all['not_equal_sig'].notna())&level_all['greater_sig'].notna()]\n",
    "\n",
    "len(level_all)\n",
    "\n",
    "level_all.to_csv('data/testReport_level_all.csv', index=False)\n",
    "\n",
    "level_all.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
